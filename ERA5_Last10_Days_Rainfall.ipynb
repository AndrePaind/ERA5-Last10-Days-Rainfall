{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "115121932426473ab4472d507213b85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbd33dd239574865bd8c35b90f5be2a1",
              "IPY_MODEL_63680f3844384c8fa34f3f4806a1d8be",
              "IPY_MODEL_9599f6eb064148f48b5d3af696aea2fb"
            ],
            "layout": "IPY_MODEL_0834b0dac8df447482cbed2e87160ad3"
          }
        },
        "cbd33dd239574865bd8c35b90f5be2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d16938c639d94329a6e694ba05ab63e7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bc4cfccdb8a24b3ba07305f7581a8e16",
            "value": "84edf48f3a2bc69638921c5e243561ec.nc:‚Äá100%"
          }
        },
        "63680f3844384c8fa34f3f4806a1d8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2253b5473bb54d059eb4c900aa1d9cab",
            "max": 87471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33e68a7f73d846c5bbb2aec4dde6c52d",
            "value": 87471
          }
        },
        "9599f6eb064148f48b5d3af696aea2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa74d193143422aa15dea82907c8b09",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_238a97151905414cb130e75e75856ea1",
            "value": "‚Äá85.4k/85.4k‚Äá[00:00&lt;00:00,‚Äá138kB/s]"
          }
        },
        "0834b0dac8df447482cbed2e87160ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d16938c639d94329a6e694ba05ab63e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc4cfccdb8a24b3ba07305f7581a8e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2253b5473bb54d059eb4c900aa1d9cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33e68a7f73d846c5bbb2aec4dde6c52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fa74d193143422aa15dea82907c8b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "238a97151905414cb130e75e75856ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrePaind/ERA5-Last10-Days-Rainfall/blob/main/ERA5_Last10_Days_Rainfall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0WpKbisRLAb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666,
          "referenced_widgets": [
            "115121932426473ab4472d507213b85d",
            "cbd33dd239574865bd8c35b90f5be2a1",
            "63680f3844384c8fa34f3f4806a1d8be",
            "9599f6eb064148f48b5d3af696aea2fb",
            "0834b0dac8df447482cbed2e87160ad3",
            "d16938c639d94329a6e694ba05ab63e7",
            "bc4cfccdb8a24b3ba07305f7581a8e16",
            "2253b5473bb54d059eb4c900aa1d9cab",
            "33e68a7f73d846c5bbb2aec4dde6c52d",
            "3fa74d193143422aa15dea82907c8b09",
            "238a97151905414cb130e75e75856ea1"
          ]
        },
        "outputId": "777392fa-dc65-4046-a733-0a768303190b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0müìÅ Please upload your locations file (e.g. 'All Locations Colombia.csv')...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e6d4d7a6-0727-4583-be15-51ba2798fa16\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e6d4d7a6-0727-4583-be15-51ba2798fa16\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving All Locations Colombia - All Locations Colombia.csv to All Locations Colombia - All Locations Colombia.csv\n",
            "‚úÖ Using locations file: All Locations Colombia - All Locations Colombia.csv\n",
            "‚úÖ Loaded 1123 points. BBOX [N,W,S,E]: [14.3540153, -82.705052, -5.203165, -66.0464591]\n",
            "‚úÖ CDS API configured with key 'CopernicusATRAM'\n",
            "‚úÖ Google Drive / Sheets auth OK\n",
            "üìÖ Using window from 2025-11-04 to 2025-11-13 (10 days)\n",
            "üóìÔ∏è Year-month combinations: [(2025, 11)]\n",
            "‚¨áÔ∏è Downloading ERA5 daily stats for 2025-11 days [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-14 18:16:04,586 INFO Request ID is 8284433c-9961-4d76-9b01-557a2c49aa86\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 8284433c-9961-4d76-9b01-557a2c49aa86\n",
            "2025-11-14 18:16:04,739 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2025-11-14 18:16:26,454 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2025-11-14 18:16:37,980 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "84edf48f3a2bc69638921c5e243561ec.nc:   0%|          | 0.00/85.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "115121932426473ab4472d507213b85d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üïí Resulting time steps: ['2025-11-04T00:00:00.000000000' '2025-11-05T00:00:00.000000000'\n",
            " '2025-11-06T00:00:00.000000000' '2025-11-07T00:00:00.000000000'\n",
            " '2025-11-08T00:00:00.000000000']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting last 10 days: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1123/1123 [00:11<00:00, 94.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ CSV saved: /content/era5_municipalities_points_daily_rain_mm_last10days_until_20251113.csv  (5615 rows)\n",
            "üìÑ Created spreadsheet 'ERA5_Rainfall_last10days_until_20251113' in your Drive.\n",
            "‚úÖ Uploaded raw data to Google Sheets ‚Üí ERA5_Rainfall_last10days_until_20251113 / data\n",
            "‚úÖ Pivot table created ‚Üí sheet 'pivot' (municipalities x dates, SUM(tp_mm))\n",
            "üîó Google Sheet link: https://docs.google.com/spreadsheets/d/1PE0YKTa9Cc0CFF_MeBmTkTWDkBWb3IBNufGrvLNWVyE\n",
            "\n",
            "üéâ Done. Last 10 days of DAILY TOTAL rainfall (mm/day) exported to CSV and Google Sheet with pivot.\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# ERA5 Daily Rainfall (mm/day) ‚Äî LAST 10 DAYS\n",
        "# Robust to mixed lon conventions and tiny lat edge differences.\n",
        "#\n",
        "# Input: upload \"All Locations Colombia.csv\" via Colab file picker\n",
        "# Output:\n",
        "#   - CSV:  /content/era5_municipalities_points_daily_rain_mm_last10days_until_YYYYMMDD.csv\n",
        "#   - Google Sheet: ERA5_Rainfall_last10days_until_YYYYMMDD\n",
        "#       * Sheet \"data\": raw table\n",
        "#       * Sheet \"pivot\": municipalities x days, SUM(tp_mm)\n",
        "#\n",
        "# Columns in \"data\": date, Codigo_DA, DANE, department, municipality, lat, lon, tp_mm\n",
        "# ============================================\n",
        "\n",
        "# ---- SETTINGS ----\n",
        "PAD_DEG              = 1.0\n",
        "SPREADSHEET_BASENAME = \"ERA5_Rainfall\"\n",
        "\n",
        "# ---- INSTALLS ----\n",
        "!pip -q install -U cdsapi xarray netCDF4 pandas tqdm gspread gspread_dataframe\n",
        "\n",
        "# ---- IMPORTS ----\n",
        "import os, re\n",
        "from datetime import date, timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------- UPLOAD LOCATIONS CSV ----------\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üìÅ Please upload your locations file (e.g. 'All Locations Colombia.csv')...\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise RuntimeError(\"No file uploaded. Please upload your locations CSV.\")\n",
        "\n",
        "CSV_PATH = list(uploaded.keys())[0]\n",
        "print(f\"‚úÖ Using locations file: {CSV_PATH}\")\n",
        "\n",
        "# ---------- READ & CLEAN CSV ----------\n",
        "def _norm(s):\n",
        "    return (s.strip().lower()\n",
        "            .replace(\"√≥\",\"o\").replace(\"√°\",\"a\").replace(\"√©\",\"e\").replace(\"√≠\",\"i\").replace(\"√∫\",\"u\")\n",
        "            .replace(\"√Ø\",\"i\").replace(\"√∂\",\"o\").replace(\"√º\",\"u\"))\n",
        "\n",
        "read_ok, df_raw, last_err = False, None, None\n",
        "for enc in (\"utf-8\",\"utf-8-sig\",\"latin-1\"):\n",
        "    for sep in [\",\",\";\",\"\\t\",\"|\"]:\n",
        "        try:\n",
        "            tmp = pd.read_csv(CSV_PATH, sep=sep, encoding=enc)\n",
        "            cols_low = [_norm(c) for c in tmp.columns]\n",
        "            ok = (\n",
        "                any(\"municipio\" in c for c in cols_low) and\n",
        "                any((\"departamen\" in c) or (\"departamento\" in c) or (\"depto\" in c) for c in cols_low) and\n",
        "                any(c in {\"codigo da\",\"codigo_da\",\"codigo da.\",\"c√≥digo da\",\"codigo_da.\"} for c in cols_low) and\n",
        "                any(c in {\"dane\",\"codigo dane\",\"codigo_dane\",\"c√≥digo dane\"} for c in cols_low) and\n",
        "                any(c in {\"new_lat\",\"lat\",\"latitude\"} for c in cols_low) and\n",
        "                any(c in {\"new_lon\",\"lon\",\"longitude\"} for c in cols_low)\n",
        "            )\n",
        "            if ok:\n",
        "                df_raw = tmp.copy(); read_ok = True; break\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "    if read_ok: break\n",
        "if not read_ok:\n",
        "    raise ValueError(f\"Cannot read '{CSV_PATH}'. Last error: {last_err}\")\n",
        "\n",
        "df_norm = df_raw.copy()\n",
        "df_norm.columns = [_norm(c) for c in df_norm.columns]\n",
        "\n",
        "def pick(opts):\n",
        "    for o in opts:\n",
        "        if o in df_norm.columns: return o\n",
        "    return None\n",
        "\n",
        "c_codigo_da = pick([\"codigo da\",\"codigo_da\",\"codigo da.\",\"c√≥digo da\",\"codigo_da.\"])\n",
        "c_dane      = pick([\"dane\",\"codigo dane\",\"codigo_dane\",\"c√≥digo dane\"])\n",
        "c_muni      = pick([\"municipio\"])\n",
        "c_dept      = pick([\"departamen\",\"departamento\",\"depto\"])\n",
        "c_lat       = pick([\"new_lat\",\"lat\",\"latitude\"])\n",
        "c_lon       = pick([\"new_lon\",\"lon\",\"longitude\"])\n",
        "if None in [c_codigo_da,c_dane,c_muni,c_dept,c_lat,c_lon]:\n",
        "    raise ValueError(f\"Missing required columns. Found: {list(df_norm.columns)}\")\n",
        "\n",
        "df = df_norm[[c_codigo_da,c_dane,c_dept,c_muni,c_lat,c_lon]].copy()\n",
        "df.columns = [\"Codigo_DA\",\"DANE\",\"department\",\"municipality\",\"lat_raw\",\"lon_raw\"]\n",
        "\n",
        "def clean_coord(x):\n",
        "    if pd.isna(x): return np.nan\n",
        "    s = str(x).strip().replace(\"\\u00A0\",\" \").replace(\" \",\"\")\n",
        "    s = s.replace(\"¬∞\",\"\").replace(\"'\",\"\").replace(\"‚Äô\",\"\").replace(\"‚Äù\",\"\").replace(\"‚Äú\",\"\").replace(\"\\\"\",\"\")\n",
        "    s = s.replace(\",\", \".\")\n",
        "    m = re.match(r\"^-?\\d+(\\.\\d+)?\", s)\n",
        "    return float(m.group(0)) if m else np.nan\n",
        "\n",
        "df[\"lat\"] = df[\"lat_raw\"].apply(clean_coord)\n",
        "df[\"lon\"] = df[\"lon_raw\"].apply(clean_coord)\n",
        "\n",
        "# fix swapped lat/lon if needed\n",
        "swap_mask = (df[\"lat\"].abs() > 90) & (df[\"lon\"].abs() <= 90)\n",
        "df.loc[swap_mask, [\"lat\",\"lon\"]] = df.loc[swap_mask, [\"lon\",\"lat\"]].values\n",
        "\n",
        "df[\"Codigo_DA\"] = df[\"Codigo_DA\"].astype(str).str.strip()\n",
        "df[\"DANE\"]      = df[\"DANE\"].astype(str).str.strip()\n",
        "df = df.dropna(subset=[\"lat\",\"lon\"])\n",
        "df = df[df[\"lat\"].between(-90,90) & df[\"lon\"].between(-180,180)].copy()\n",
        "df = df.drop_duplicates(subset=[\"Codigo_DA\",\"DANE\",\"lat\",\"lon\"]).reset_index(drop=True)\n",
        "\n",
        "# ---------- BBOX ----------\n",
        "PAD = PAD_DEG\n",
        "AREA = [float(df[\"lat\"].max()+PAD), float(df[\"lon\"].min()-PAD),\n",
        "        float(df[\"lat\"].min()-PAD), float(df[\"lon\"].max()+PAD)]  # [N,W,S,E]\n",
        "pts = df[[\"Codigo_DA\",\"DANE\",\"department\",\"municipality\",\"lat\",\"lon\"]].copy()\n",
        "print(f\"‚úÖ Loaded {len(pts)} points. BBOX [N,W,S,E]: {AREA}\")\n",
        "\n",
        "# ---------- CDS TOKEN ----------\n",
        "from google.colab import userdata\n",
        "TOKEN = userdata.get('CopernicusATRAM')\n",
        "if not TOKEN:\n",
        "    raise RuntimeError(\"Colab secret 'CopernicusATRAM' not found.\")\n",
        "os.makedirs(os.path.expanduser(\"~\"), exist_ok=True)\n",
        "with open(os.path.expanduser(\"~/.cdsapirc\"), \"w\") as f:\n",
        "    f.write(\"url: https://cds.climate.copernicus.eu/api\\n\")\n",
        "    f.write(f\"key: {TOKEN}\\n\")\n",
        "print(\"‚úÖ CDS API configured with key 'CopernicusATRAM'\")\n",
        "\n",
        "# ---------- GOOGLE AUTH ----------\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import google.auth, gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "creds, _ = google.auth.default()\n",
        "gc = gspread.authorize(creds)\n",
        "print(\"‚úÖ Google Drive / Sheets auth OK\")\n",
        "\n",
        "# ---------- ERA5 HELPERS ----------\n",
        "import cdsapi\n",
        "c = cdsapi.Client()\n",
        "BASE_OUTDIR = \"/content/era5_bbox_daily_tp_last10days\"\n",
        "os.makedirs(BASE_OUTDIR, exist_ok=True)\n",
        "\n",
        "def retrieve_month(y, m, days, target, area):\n",
        "    \"\"\"\n",
        "    Download ONLY the requested 'days' of that (year,month),\n",
        "    not the whole month.\n",
        "    \"\"\"\n",
        "    c.retrieve(\n",
        "        \"derived-era5-single-levels-daily-statistics\",\n",
        "        {\n",
        "            \"product_type\": \"reanalysis\",\n",
        "            \"variable\": [\"total_precipitation\"],\n",
        "            \"daily_statistic\": \"daily_sum\",\n",
        "            \"frequency\": \"1_hourly\",\n",
        "            \"time_zone\": \"utc+00:00\",\n",
        "            \"year\": str(y),\n",
        "            \"month\": f\"{m:02d}\",\n",
        "            \"day\": [f\"{d:02d}\" for d in days],\n",
        "            \"area\": area,        # [N, W, S, E]\n",
        "            \"format\": \"netcdf\",\n",
        "        },\n",
        "        target\n",
        "    )\n",
        "\n",
        "def _standardize_lonlat(ds: xr.Dataset) -> xr.Dataset:\n",
        "    # ensure coordinate names\n",
        "    if \"longitude\" not in ds.coords and \"lon\" in ds.coords:\n",
        "        ds = ds.rename({\"lon\":\"longitude\"})\n",
        "    if \"latitude\"  not in ds.coords and \"lat\" in ds.coords:\n",
        "        ds = ds.rename({\"lat\":\"latitude\"})\n",
        "    # longitude to [-180,180)\n",
        "    if \"longitude\" in ds.coords:\n",
        "        lon = ds[\"longitude\"]\n",
        "        lon_std = ((lon + 180.0) % 360.0) - 180.0\n",
        "        ds = ds.assign_coords(longitude=lon_std).sortby(\"longitude\")\n",
        "        # drop dupes after wrap\n",
        "        lon_vals = np.round(ds[\"longitude\"].values, 6)\n",
        "        _, idx = np.unique(lon_vals, return_index=True)\n",
        "        if len(idx) != ds.sizes[\"longitude\"]:\n",
        "            ds = ds.isel(longitude=np.sort(idx))\n",
        "    # latitude sorted descending (ERA5 convention)\n",
        "    if \"latitude\" in ds.coords:\n",
        "        ds = ds.sortby(\"latitude\", ascending=False)\n",
        "    return ds\n",
        "\n",
        "def _preprocess_month(ds: xr.Dataset) -> xr.Dataset:\n",
        "    ds = _standardize_lonlat(ds)\n",
        "    if \"valid_time\" in ds.coords and \"time\" not in ds.coords:\n",
        "        ds = ds.rename({\"valid_time\":\"time\"})\n",
        "    if \"number\" in ds.dims:\n",
        "        ds = ds.isel(number=0)\n",
        "    keep = [v for v in ds.data_vars if v in (\"tp\",\"total_precipitation\")]\n",
        "    ds = ds[keep].sortby(\"time\")\n",
        "    # round coords to reduce fp jitter\n",
        "    if \"latitude\" in ds.coords:\n",
        "        ds = ds.assign_coords(latitude=np.round(ds[\"latitude\"].values, 5))\n",
        "    if \"longitude\" in ds.coords:\n",
        "        ds = ds.assign_coords(longitude=np.round(ds[\"longitude\"].values, 5))\n",
        "    return ds\n",
        "\n",
        "def open_tp(files):\n",
        "    \"\"\"Open all month files on a common grid and return tp_mm (mm/day).\"\"\"\n",
        "    ds0 = _preprocess_month(xr.open_dataset(files[0]))\n",
        "    lat_template = ds0[\"latitude\"].values\n",
        "    lon_template = ds0[\"longitude\"].values\n",
        "\n",
        "    dsets = [ds0]\n",
        "    for f in files[1:]:\n",
        "        dsi = _preprocess_month(xr.open_dataset(f))\n",
        "        dsi = dsi.reindex(latitude=lat_template, longitude=lon_template,\n",
        "                          method=\"nearest\", tolerance=1e-3)\n",
        "        dsets.append(dsi)\n",
        "\n",
        "    ds = xr.concat(dsets, dim=\"time\", data_vars=\"minimal\", coords=\"minimal\",\n",
        "                   compat=\"override\", join=\"override\")\n",
        "    var = \"tp\" if \"tp\" in ds.data_vars else \"total_precipitation\"\n",
        "    da = ds[var]\n",
        "    # m/day ‚Üí mm/day\n",
        "    return (da * 1000.0).rename(\"tp_mm\")\n",
        "\n",
        "def norm_lon_factory(tp_da):\n",
        "    # grid already standardized to [-180,180)\n",
        "    return lambda lon: ((lon + 180.0) % 360.0) - 180.0\n",
        "\n",
        "# ---------- LAST 10 DAYS WINDOW ----------\n",
        "# ERA5 is typically complete up to yesterday ‚Üí we stop at yesterday.\n",
        "end_date = date.today() - timedelta(days=1)\n",
        "start_date = end_date - timedelta(days=9)\n",
        "print(f\"üìÖ Using window from {start_date} to {end_date} (10 days)\")\n",
        "\n",
        "# List of individual dates\n",
        "last10 = []\n",
        "cur = start_date\n",
        "while cur <= end_date:\n",
        "    last10.append(cur)\n",
        "    cur += timedelta(days=1)\n",
        "\n",
        "# Unique (year, month) pairs in that 10-day window\n",
        "ym_set = sorted({(d.year, d.month) for d in last10})\n",
        "print(\"üóìÔ∏è Year-month combinations:\", ym_set)\n",
        "\n",
        "def days_for_month_in_window(y, m, dates):\n",
        "    return sorted({d.day for d in dates if d.year == y and d.month == m})\n",
        "\n",
        "# ---------- DOWNLOAD ONLY THE NEEDED DAYS ----------\n",
        "files = []\n",
        "for (yy, mm) in ym_set:\n",
        "    days = days_for_month_in_window(yy, mm, last10)\n",
        "    outdir = os.path.join(BASE_OUTDIR, f\"{yy}\")\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    tgt = f\"{outdir}/era5_tp_daily_sum_{yy}_{mm:02d}.nc\"\n",
        "    if not os.path.exists(tgt):\n",
        "        print(f\"‚¨áÔ∏è Downloading ERA5 daily stats for {yy}-{mm:02d} days {days}\")\n",
        "        retrieve_month(yy, mm, days, tgt, AREA)\n",
        "    else:\n",
        "        print(f\"‚úÖ Already present: {yy}-{mm:02d} (file reused)\")\n",
        "    files.append(tgt)\n",
        "\n",
        "# ---------- OPEN + FILTER TO LAST 10 DAYS (SAFETY) ----------\n",
        "tp = open_tp(files)\n",
        "norm_lon = norm_lon_factory(tp)\n",
        "\n",
        "tp_10 = tp.sel(time=slice(str(start_date), str(end_date)))\n",
        "print(\"üïí Resulting time steps:\", tp_10[\"time\"].values)\n",
        "\n",
        "# ---------- EXTRACT SERIES FOR EACH POINT ----------\n",
        "rows = []\n",
        "for _, r in tqdm(pts.iterrows(), total=len(pts), desc=\"Extracting last 10 days\"):\n",
        "    series = tp_10.sel(\n",
        "        latitude=float(r[\"lat\"]),\n",
        "        longitude=norm_lon(float(r[\"lon\"])),\n",
        "        method=\"nearest\"\n",
        "    )\n",
        "    # ‚úÖ enforce DAILY TOTALS (mm/day)\n",
        "    series_daily = series.resample(time=\"1D\").sum()\n",
        "\n",
        "    df_pt = series_daily.to_dataframe().reset_index()[[\"time\",\"tp_mm\"]]\n",
        "    df_pt.insert(0, \"Codigo_DA\", r[\"Codigo_DA\"])\n",
        "    df_pt.insert(1, \"DANE\", r[\"DANE\"])\n",
        "    df_pt.insert(2, \"department\", r[\"department\"])\n",
        "    df_pt.insert(3, \"municipality\", r[\"municipality\"])\n",
        "    df_pt[\"lat\"] = float(r[\"lat\"])\n",
        "    df_pt[\"lon\"] = float(r[\"lon\"])\n",
        "    rows.append(df_pt)\n",
        "\n",
        "all_df = pd.concat(rows, ignore_index=True).rename(columns={\"time\":\"date\"})\n",
        "all_df = all_df[[\"date\",\"Codigo_DA\",\"DANE\",\"department\",\"municipality\",\"lat\",\"lon\",\"tp_mm\"]]\n",
        "all_df = all_df.sort_values([\"Codigo_DA\",\"date\"]).reset_index(drop=True)\n",
        "\n",
        "# ---------- SAVE CSV ----------\n",
        "csv_end_str = end_date.strftime(\"%Y%m%d\")\n",
        "out_csv = f\"/content/era5_municipalities_points_daily_rain_mm_last10days_until_{csv_end_str}.csv\"\n",
        "all_df.to_csv(out_csv, index=False)\n",
        "print(f\"‚úÖ CSV saved: {out_csv}  ({len(all_df)} rows)\")\n",
        "\n",
        "# ---------- GOOGLE SHEET (RAW DATA + PIVOT) ----------\n",
        "sheet_name = f\"{SPREADSHEET_BASENAME}_last10days_until_{csv_end_str}\"\n",
        "\n",
        "try:\n",
        "    sh = gc.open(sheet_name)\n",
        "    try:\n",
        "        ws_old = sh.worksheet(\"data\"); sh.del_worksheet(ws_old)\n",
        "    except gspread.WorksheetNotFound:\n",
        "        pass\n",
        "except gspread.SpreadsheetNotFound:\n",
        "    sh = gc.create(sheet_name)\n",
        "    print(f\"üìÑ Created spreadsheet '{sheet_name}' in your Drive.\")\n",
        "\n",
        "# \"data\" sheet with flat table\n",
        "ws_data = sh.add_worksheet(title=\"data\", rows=\"1000\", cols=\"12\")\n",
        "set_with_dataframe(ws_data, all_df, include_index=False, resize=True)\n",
        "print(f\"‚úÖ Uploaded raw data to Google Sheets ‚Üí {sheet_name} / data\")\n",
        "\n",
        "# Create / recreate \"pivot\" sheet\n",
        "try:\n",
        "    ws_pivot_old = sh.worksheet(\"pivot\")\n",
        "    sh.del_worksheet(ws_pivot_old)\n",
        "except gspread.WorksheetNotFound:\n",
        "    pass\n",
        "ws_pivot = sh.add_worksheet(title=\"pivot\", rows=\"1000\", cols=\"26\")\n",
        "\n",
        "# Build pivot table:\n",
        "# - rows: municipality (column index 4)\n",
        "# - columns: date (column index 0)\n",
        "# - values: SUM of tp_mm (column index 7)\n",
        "nrows = len(all_df) + 1  # + header row\n",
        "data_sheet_id = ws_data.id\n",
        "pivot_sheet_id = ws_pivot.id\n",
        "\n",
        "pivot_body = {\n",
        "    \"requests\": [\n",
        "        {\n",
        "            \"updateCells\": {\n",
        "                \"start\": {\n",
        "                    \"sheetId\": pivot_sheet_id,\n",
        "                    \"rowIndex\": 0,\n",
        "                    \"columnIndex\": 0,\n",
        "                },\n",
        "                \"rows\": [\n",
        "                    {\n",
        "                        \"values\": [\n",
        "                            {\n",
        "                                \"pivotTable\": {\n",
        "                                    \"source\": {\n",
        "                                        \"sheetId\": data_sheet_id,\n",
        "                                        \"startRowIndex\": 0,\n",
        "                                        \"startColumnIndex\": 0,\n",
        "                                        \"endRowIndex\": nrows,\n",
        "                                        \"endColumnIndex\": 8,  # A:H\n",
        "                                    },\n",
        "                                    \"rows\": [\n",
        "                                        {\n",
        "                                            \"sourceColumnOffset\": 4,  # municipality\n",
        "                                            \"showTotals\": True,\n",
        "                                            \"sortOrder\": \"ASCENDING\",\n",
        "                                        }\n",
        "                                    ],\n",
        "                                    \"columns\": [\n",
        "                                        {\n",
        "                                            \"sourceColumnOffset\": 0,  # date\n",
        "                                            \"showTotals\": True,\n",
        "                                            \"sortOrder\": \"ASCENDING\",\n",
        "                                        }\n",
        "                                    ],\n",
        "                                    \"values\": [\n",
        "                                        {\n",
        "                                            \"summarizeFunction\": \"SUM\",\n",
        "                                            \"sourceColumnOffset\": 7,  # tp_mm\n",
        "                                            \"name\": \"Total Rain (mm)\",\n",
        "                                        }\n",
        "                                    ],\n",
        "                                }\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                ],\n",
        "                \"fields\": \"pivotTable\",\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "sh.batch_update(pivot_body)\n",
        "print(\"‚úÖ Pivot table created ‚Üí sheet 'pivot' (municipalities x dates, SUM(tp_mm))\")\n",
        "\n",
        "# üîó Show Google Sheet URL\n",
        "print(f\"üîó Google Sheet link: {sh.url}\")\n",
        "\n",
        "print(\"\\nüéâ Done. Last 10 days of DAILY TOTAL rainfall (mm/day) exported to CSV and Google Sheet with pivot.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IPOKMK1nVXj4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}